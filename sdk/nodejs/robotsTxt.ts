// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as utilities from "./utilities";

/**
 * Manages robots.txt configuration for a Webflow site. This resource allows you to define crawler access rules and sitemap references.
 */
export class RobotsTxt extends pulumi.CustomResource {
    /**
     * Get an existing RobotsTxt resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, opts?: pulumi.CustomResourceOptions): RobotsTxt {
        return new RobotsTxt(name, undefined as any, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'webflow:index:RobotsTxt';

    /**
     * Returns true if the given object is an instance of RobotsTxt.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is RobotsTxt {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === RobotsTxt.__pulumiType;
    }

    /**
     * The robots.txt content in traditional format. Supports User-agent, Allow, Disallow, and Sitemap directives.
     */
    declare public readonly content: pulumi.Output<string>;
    /**
     * RFC3339 timestamp of the last modification.
     */
    declare public /*out*/ readonly lastModified: pulumi.Output<string>;
    /**
     * The Webflow site ID (24-character lowercase hexadecimal string, e.g., '5f0c8c9e1c9d440000e8d8c3').
     */
    declare public readonly siteId: pulumi.Output<string>;

    /**
     * Create a RobotsTxt resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: RobotsTxtArgs, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (!opts.id) {
            if (args?.content === undefined && !opts.urn) {
                throw new Error("Missing required property 'content'");
            }
            if (args?.siteId === undefined && !opts.urn) {
                throw new Error("Missing required property 'siteId'");
            }
            resourceInputs["content"] = args?.content;
            resourceInputs["siteId"] = args?.siteId;
            resourceInputs["lastModified"] = undefined /*out*/;
        } else {
            resourceInputs["content"] = undefined /*out*/;
            resourceInputs["lastModified"] = undefined /*out*/;
            resourceInputs["siteId"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(RobotsTxt.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * The set of arguments for constructing a RobotsTxt resource.
 */
export interface RobotsTxtArgs {
    /**
     * The robots.txt content in traditional format. Supports User-agent, Allow, Disallow, and Sitemap directives.
     */
    content: pulumi.Input<string>;
    /**
     * The Webflow site ID (24-character lowercase hexadecimal string, e.g., '5f0c8c9e1c9d440000e8d8c3').
     */
    siteId: pulumi.Input<string>;
}
